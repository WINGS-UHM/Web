---
layout: post
title: NextG UAV Detection Using an O-RAN-Controlled Reconfigurable Intelligent Surface (RIS)
description: How to create a docs site for your project with WINGS Lab 
date: 2025-09-01 00:00:00
hero_image: /assets/img/project/uav-detection.png
hero_height: is-large
hero_darken: true
image: /assets/img/project/uav-detection.png
tags: O-RAN AI-RAN Prototype UAV RIS ISAC
series: project_series_oran
excerpt: A RIS- and O-RAN–assisted Integrated Sensing and Communication (ISAC) framework is presented for high-speed UAV detection and tracking in the 3.7 GHz band. The system integrates composite OFDM–FMCW waveforms, reconfigurable intelligent surfaces (RIS), and O-RAN distributed intelligence to enable scalable, low-latency, and adaptive sensing under spectrum-sharing constraints.
author:
        - XXC
        - syu
        - sparkar
        - Yao Zheng
---

# On this Page  <!-- omit in toc -->
- [Overview](#overview)
  - [Highlights](#highlights)
- [System Architecture](#system-architecture)
- [Multi-Stage UAV Detection Strategy](#multi-stage-uav-detection-strategy)
- [RIS-Assisted Measurement Model](#ris-assisted-measurement-model)
- [Path Prediction and state change using GRU](#path-prediction-and-state-change-using-gru)


## Overview
A RIS- and O-RAN–assisted Integrated Sensing and Communication (ISAC) framework is presented for high-speed UAV detection and tracking in the 3.7 GHz band. The system integrates composite OFDM–FMCW waveforms, reconfigurable intelligent surfaces (RIS), and O-RAN distributed intelligence to enable scalable, low-latency, and adaptive sensing under spectrum-sharing constraints.

### Highlights

- Joint **RIS** and **O-RAN coordination** for wide-area UAV sensing
- Composite **OFDM–FMCW waveform** enabling range–Doppler detection
- Hierarchical, state-driven sensing strategy
- **GRU-based predictive control** for proactive RIS adaptation

## System Architecture

- Operation in the CBRS band (3.7 GHz) balances coverage and sensing resolution
- RIS enhances signal observability and mitigates LoS limitations
- O-RAN provides distributed intelligence through Near-RT and Non-RT RICs
- ISAC enables spectrum and infrastructure sharing between sensing and communication

<div style="text-align: center; margin: 1.5rem 0;">
  <img src="{{"/assets/img/uav/SystemModel.png"  | relative_url }}" 
       alt="System Architecture" 
       style="max-width: 60%; height: auto;" />
  <div style="margin-top: 0.5rem; font-size: 0.9rem; color: #444444;">
    Fig. 1. System Architecture
  </div>
</div>

## Multi-Stage UAV Detection Strategy

A four-stage state machine governs sensing resolution and resource allocation:

- Stage 0 – Idle
    - Continuous wide-area surveillance
    - Minimal sensing and RIS resources
- Stage 1 – Initial Detection
    - Coarse FMCW sweeps
    - Broad beams for rapid target discovery
- Stage 2 – Classification
    - Refined angle and velocity estimation
    - Classification between UAVs and clutter
- Stage 3 – Identification
    - Narrow beams and high SNR
    - Fine-grained trajectory and motion characterization

State transitions depend on detection confidence, SNR, QoS constraints, and resource availability.

<div style="text-align: center; margin: 1.5rem 0;">
  <img src="{{"/assets/img/uav/statemachine.png"  | relative_url }}" 
       alt="State machine for adaptive UAV sensing. Equipped with backward transitions enabled for re-verification or uncertainty handling." 
       style="max-width: 60%; height: auto;" />
  <div style="margin-top: 0.5rem; font-size: 0.9rem; color: #444444;">
    Fig. 2. State machine for adaptive UAV sensing. Equipped with backward transitions enabled for re-verification or uncertainty handling.
  </div>
</div>

## RIS-Assisted Measurement Model

- RIS configuration: 8x2 RIS elements array separated at $\lambda/2$ distance.
- Sensing resource allocation managed at each stage.
- Enables efficient trade-off between sensing precision and communication QoS

<div style="text-align: center; margin: 2rem 0;">
  <!-- Subfigures row -->
  <div style="display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap;">
    <div style="flex: 1; max-width: 32%;">
      <img src="{{"/assets/img/uav/RIS-Array-Setup.png"  | relative_url }}" alt="Subfigure A" style="width: 100%; height: auto;">
      <!-- <div style="font-size: 0.85rem; margin-top: 0.4rem; color: #555;">
      </div> -->
    </div>
    <div style="flex: 1; max-width: 32%;">
      <img src="{{"/assets/img/uav/RIS-Directivity.png"  | relative_url }}" alt="Subfigure B" style="width: 100%; height: auto;">
      <!-- <div style="font-size: 0.85rem; margin-top: 0.4rem; color: #555;"> 
      </div> -->
    </div>
    <div style="flex: 1; max-width: 32%;">
      <img src="{{"/assets/img/uav/RIS-Directivity-2.png"  | relative_url }}" alt="Subfigure C" style="width: 100%; height: auto;">
      <!-- <div style="font-size: 0.85rem; margin-top: 0.4rem; color: #555;">
        Hilbert transform and pattern normalization
      </div> -->
    </div>
  </div>
  <!-- Main caption -->
  <div style="margin-top: 0.75rem; font-size: 0.9rem; color: #444;">
    Fig. 3. An 8x2 RIS array in 3D. Simulated directivity patterns for different azimuth/elevation combinations, illustrating beamforming capabilities.
  </div>
</div>

- UAV position and velocity estimated in 3D ENU coordinates
- Range Velocity estimations
  - Beat frequency enables range estimation
  - Doppler shift provides radial velocity
- 2D Multiple Signal Classification (MUSIC) for azimuth and elevation angles extracted via array processing
<div style="text-align: center; margin: 1.5rem 0;">
  <img src="{{"/assets/img/uav/environment-4.png"  | relative_url }}" 
       alt="UAV trajectory in a 3D East-North-Up (ENU) coordinate system." 
       style="max-width: 50%; height: auto;" />
  <div style="margin-top: 0.5rem; font-size: 0.9rem; color: #444444;">
    Fig. 5.UAV trajectory in a 3D East-North-Up (ENU) coordinate system.
  </div>
</div>

## Path Prediction and state change using GRU

- SNR thresholding for UAV Detection confidence
- Resource allocation for finer sensing
- Gated Recurrent Unit (GRU) predicts next co-ordinate in 3D-space
  - Inputs: Co-ordinate window of last 64 CPIs
- Prediction latency compatible with Near-RT RIC requirements
- Enables proactive beam steering for fast UAV maneuvers
- the GRU model achieves a training RMSE of **0.0663** and a validation RMSE of **0.1363**
  

<div style="text-align: center; margin: 2rem 0;">
  <!-- Subfigures row -->
  <div style="display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap;">
    <div style="flex: 1; max-width: 48%;">
      <img src="{{"/assets/img/uav/Range-Speedplot-3.png"  | relative_url }}" alt="Subfigure A" style="width: 100%; height: auto;">
      <div style="font-size: 0.85rem; margin-top: 0.4rem; color: #555;">
        Processed result showing range-velocity map
      </div>
    </div>
    <div style="flex: 1; max-width: 48%;">
      <img src="{{"/assets/img/uav/UAV2-long.png"  | relative_url }}" alt="Subfigure B" style="width: 100%; height: auto;">
      <div style="font-size: 0.85rem; margin-top: 0.4rem; color: #555;"> 
      Predicted path using GRU
      </div>
    </div>
  <!-- Main caption -->
  <div style="margin-top: 0.75rem; font-size: 0.9rem; color: #444;">
    Fig. 3. An 8x2 RIS array in 3D. Simulated directivity patterns for different azimuth/elevation combinations, illustrating beamforming capabilities.
  </div>
</div>
